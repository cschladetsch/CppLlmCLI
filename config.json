{
  "provider": "groq",
  "groq": {
    "model": "llama-3.3-70b-versatile",
    "temperature": 0.7,
    "max_tokens": 2048,
    "api_url": "https://api.groq.com"
  },
  "together": {
    "model": "meta-llama/Llama-2-70b-chat-hf",
    "temperature": 0.7,
    "max_tokens": 2048,
    "api_url": "https://api.together.xyz/v1"
  },
  "ollama": {
    "model": "llama3.1",
    "temperature": 0.7,
    "max_tokens": 2048,
    "api_url": "http://localhost:11434"
  },
  "repl": {
    "history_file": "~/.llm_repl_history",
    "max_history": 100,
    "system_prompt": "You are a helpful AI assistant.",
    "streaming": false,
    "markdown_rendering": true,
    "prompt_prefix": "> ",
    "ai_prefix": "AI: "
  }
}